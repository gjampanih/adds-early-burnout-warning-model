{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/PycharmProjects/adds-early-burnout-warning-model/venv/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "def postgresql_engine(user, pwd, host, port, dbname):\n",
    "    # Need psycopg2-binary package\n",
    "    sql_engine = create_engine('postgres://' + user + ':' + pwd + '@' + host + ':' + port + '/' + dbname, echo=False)\n",
    "    return sql_engine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DB username & password\n",
    "import getpass\n",
    "\n",
    "username = getpass.getpass()\n",
    "password = getpass.getpass()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# misc db parameters\n",
    "url= 'adds-postgres-dev.cfgztrijqgvp.us-east-1.rds.amazonaws.com'\n",
    "database= 'musiclab'\n",
    "port= '5432'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_query = '''\n",
    "Select *\n",
    "from adds_temp.ebw_metric_analysis as ema\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "engine = postgresql_engine(username, password, url, port, database)\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        df_ebw_metrics = pd.read_sql(data_query, con=conn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df_ebw_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics.drop_duplicates(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# song-artist lookup\n",
    "song_query = '''\n",
    "Select mediabase_id, song_name, artist_name\n",
    "from data.songs_v as sv\n",
    "'''\n",
    "engine = postgresql_engine(username, password, url, port, database)\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        df_song_lookup = pd.read_sql(song_query, con=conn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_song_lookup.set_index(['mediabase_id'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_song_lookup.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract all formats\n",
    "all_formats = list(pd.unique(df_ebw_metrics['format_code']))\n",
    "all_formats.sort()\n",
    "all_formats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define major formats\n",
    "major_formats = ['C1', 'H1', 'U1']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Unique songs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics.groupby(['format_code']).apply(lambda x:(len(pd.unique(x['mediabase_id'])), len(pd.unique(x['station_id']))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Unique songs and stations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics.groupby(['format_code']).apply(lambda x:len((x[['mediabase_id', 'station_id']].drop_duplicates())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculated fields for analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Look at two appearances in top quintile of callout research\n",
    "df_pop_quintile = pd.DataFrame(df_ebw_metrics[~pd.isna(df_ebw_metrics['pop'])].groupby(['format_code', 'cmm_station_calls', 'week_dt']).apply(lambda x: np.quantile(x['pop'], 0.80)), columns=['top_quintile_cutoff'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_pop_quintile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics['is_top_quintile'] = df_ebw_metrics.join(df_pop_quintile, on=['format_code', 'cmm_station_calls', 'week_dt'], rsuffix='_r').apply(lambda x: int(x['pop'] >= x['top_quintile_cutoff']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics['week_dt'] = pd.to_datetime(df_ebw_metrics['week_dt'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics.sort_values(by=['format_code', 'call_letters', 'mediabase_id', 'week_dt'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics['num_top_quintile'] = df_ebw_metrics.groupby(['format_code', 'call_letters', 'mediabase_id'])['is_top_quintile'].cumsum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics['cuml_spins_non_on'] = df_ebw_metrics.groupby(['format_code', 'call_letters', 'mediabase_id'])['spins_non_on'].cumsum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "100*(int(np.max(df_ebw_metrics['cuml_spins_non_on'])/100) + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics['cuml_spins_bucket'] = pd.cut(df_ebw_metrics['cuml_spins_non_on'], bins=pd.interval_range(start=0, end=100*(int(np.max(df_ebw_metrics['cuml_spins_non_on'])/100) + 1), freq=100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics['weeks_since_release'] = ((df_ebw_metrics['week_dt'] - pd.to_datetime(df_ebw_metrics['song_release_date']))/np.timedelta64(1, 'W')).apply(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics = df_ebw_metrics.join(df_song_lookup, on=['mediabase_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ddl_range = np.arange(15, 26, 1)\n",
    "f2b_range = np.arange(0.85, 1.18, 0.03)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ddl_geq_cols = ['ddl_geq_' + str(int(i)) for i in ddl_range]\n",
    "ddl_track_cols = ['ddl_track_' + str(int(i)) for i in ddl_range]\n",
    "\n",
    "f2b_leq_cols = ['f2b_leq_' + '%.2f'%i for i in f2b_range]\n",
    "f2b_track_cols = ['f2b_track_' + '%.2f'%i  for i in f2b_range]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(ddl_range)):\n",
    "    df_ebw_metrics[ddl_geq_cols[i]] = df_ebw_metrics['ddl_metric'].apply(lambda x: int(x >= ddl_range[i]))\n",
    "    df_ebw_metrics[ddl_track_cols[i]] = df_ebw_metrics.groupby(['format_code', 'call_letters', 'mediabase_id'])[ddl_geq_cols[i]].cumsum()\n",
    "\n",
    "    df_ebw_metrics[f2b_leq_cols[i]] = df_ebw_metrics['f2b_ratio'].apply(lambda x: int(x <= f2b_range[i]))\n",
    "    df_ebw_metrics[f2b_track_cols[i]] = df_ebw_metrics.groupby(['format_code', 'call_letters', 'mediabase_id'])[f2b_leq_cols[i]].cumsum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics[df_ebw_metrics['f2b_track_1.00'] >= 2].groupby(['format_code', 'call_letters', 'mediabase_id']).agg({'week_dt':np.min, 'cuml_spins_non_on': np.min, 'weeks_since_release': np.min})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ebw_metrics[(df_ebw_metrics['mediabase_id']==2436510) & (df_ebw_metrics['call_letters'] == 'KIIS-FM')].head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyze Favorite, DDL and F2B ratio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='white')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Look a distribution of DDL and F2b for major formats\n",
    "for fmt in major_formats:\n",
    "    idx = (df_ebw_metrics['format_code']==fmt) & (~pd.isna(df_ebw_metrics['pop']))\n",
    "    fig = plt.figure(figsize=(12.5, 5))\n",
    "    ax1= plt.subplot(1,3,1)\n",
    "    df_ebw_metrics[idx]['ddl_metric'].plot(ax=ax1, kind='hist', bins=np.arange(0,45,5))\n",
    "\n",
    "    ax2= plt.subplot(1,3,2)\n",
    "    df_ebw_metrics[idx]['ddl_metric'].plot(ax=ax2, kind='hist', bins=np.arange(0,45,5))\n",
    "\n",
    "    ax3=plt.subplot(1,3,3)\n",
    "    df_ebw_metrics[idx]['f2b_ratio'].plot(ax=ax3, kind='hist', bins=np.arange(0,20,0.5))\n",
    "\n",
    "    ax1.set_aspect(1/ax1.get_data_ratio())\n",
    "    ax2.set_aspect(1/ax2.get_data_ratio())\n",
    "    ax3.set_aspect(1/ax3.get_data_ratio())\n",
    "\n",
    "    plt.suptitle(fmt)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot out favorite, f2b ratio, and pop scoress\n",
    "for fmt in major_formats:\n",
    "    df_temp = df_ebw_metrics[(df_ebw_metrics['format_code']==fmt) & (~pd.isna(df_ebw_metrics['pop'])) & (df_ebw_metrics['f2b_ratio']<=2)]\n",
    "\n",
    "    # Discretize DDL and F2B\n",
    "    df_temp.loc[:, 'fav_bucket'] = pd.cut(df_temp['fav_metric'], bins=pd.interval_range(start=0, end=40, freq=5))\n",
    "    df_temp.loc[:, 'ddl_bucket'] = pd.cut(df_temp['ddl_metric'], bins=pd.interval_range(start=0, end=40, freq=5))\n",
    "\n",
    "    df_temp_agg_f2b = pd.pivot_table(df_temp.groupby(['ddl_bucket', 'fav_bucket']).agg({'f2b_ratio': np.mean}).reset_index(), index = ['fav_bucket'], columns=['ddl_bucket'])\n",
    "    df_temp_agg_pop = pd.pivot_table(df_temp.groupby(['ddl_bucket', 'fav_bucket']).agg({'pop': np.median}).reset_index(), index = ['fav_bucket'], columns=['ddl_bucket'])\n",
    "\n",
    "    # print(df_temp_agg_f2b)\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    im = ax1.imshow(df_temp_agg_f2b, origin='lower')\n",
    "\n",
    "    # Show all ticks and label them with the respective list entries\n",
    "    ax1.set_yticks(ticks=np.arange(len(df_temp_agg_f2b.index)), labels=df_temp_agg_f2b.index)\n",
    "    ax1.set_xticks(ticks=np.arange(len( df_temp_agg_f2b.columns)), labels=['(' + str(i.left) + ',' +  str(i.right) + ']' for (j,i) in df_temp_agg_f2b.columns])\n",
    "    #\n",
    "    # # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax1.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    #\n",
    "    # # Loop over data dimensions and create text annotations.\n",
    "    for i in np.arange(len(df_temp_agg_f2b.columns)):\n",
    "        for j in np.arange(len(df_temp_agg_f2b.index)):\n",
    "            text = ax1.text(i, j, \"%.2f\"%df_temp_agg_f2b.iloc[j, i],\n",
    "                           ha=\"center\", va=\"center\", color=\"w\", fontsize='small')\n",
    "\n",
    "    ax1.set_title(\"F2B ratio\")\n",
    "    ax1.set_aspect(1/ax1.get_data_ratio())\n",
    "    ax1.grid(False)\n",
    "\n",
    "    # plot pop\n",
    "    ax2 = plt.subplot(1,2,2)\n",
    "    im = ax2.imshow(df_temp_agg_pop, origin='lower')\n",
    "\n",
    "    # Show all ticks and label them with the respective list entries\n",
    "    ax2.set_yticks(ticks=np.arange(len(df_temp_agg_pop.index)), labels=df_temp_agg_pop.index)\n",
    "    ax2.set_xticks(ticks=np.arange(len( df_temp_agg_pop.columns)), labels=['(' + str(i.left) + ',' +  str(i.right) + ']' for (j,i) in df_temp_agg_pop.columns])\n",
    "    #\n",
    "    # # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax2.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    #\n",
    "    # # Loop over data dimensions and create text annotations.\n",
    "    for i in np.arange(len(df_temp_agg_pop.columns)):\n",
    "        for j in np.arange(len(df_temp_agg_pop.index)):\n",
    "            text = ax2.text(i, j, \"%.2f\"%df_temp_agg_pop.iloc[j, i],\n",
    "                           ha=\"center\", va=\"center\", color=\"w\", fontsize = 'x-small')\n",
    "\n",
    "    ax2.set_title(\"Avg. Pop \")\n",
    "    ax2.set_aspect(1/ax2.get_data_ratio())\n",
    "    ax2.grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Examples of Burnout and indicators (spins, market spins, streams)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# explore songs suggested by Marc\n",
    "artists = ['WALKER HAYES', 'SAM HUNT', 'GABBY BARRETT']\n",
    "idx = (df_ebw_metrics['artist_name'].isin(artists)) & (df_ebw_metrics['weeks_since_release'] <= 104)\n",
    "df_ebw_metrics[idx].groupby (['mediabase_id', 'song_name', 'artist_name']).agg({'cuml_spins_non_on': np.max, 'song_release_date': np.min}).reset_index().sort_values(by=['artist_name', 'cuml_spins_non_on'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "songs_sample = ['Fancy Like', 'Hard To Forget', 'Kinfolks', 'Breaking Up Was Easy In The...', '23', 'The Good Ones', 'I Hope f/Charlie Puth']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = (df_ebw_metrics['ddl_track_20'] >= 2) & (df_ebw_metrics['format_code'] == 'C1') & (df_ebw_metrics['song_name'].isin(songs_sample))\n",
    "\n",
    "df_brn_temp = df_ebw_metrics.loc[idx].groupby(['format_code', 'call_letters', 'mediabase_id']).agg({'week_dt': np.min})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_brn_instances = df_ebw_metrics.join(df_brn_temp, on=['format_code', 'call_letters', 'mediabase_id'], how='inner', rsuffix='_r')[['mediabase_id', 'call_letters', 'week_dt', 'song_name', 'artist_name', 'pop', 'ddl_metric', 'fav_metric', 'f2b_ratio', 'spins_non_on', 'cuml_spins_non_on', 'MarketSpinsToDate', 'stream_count']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_brn_instances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Inspect Data for Gabby Barrett (I Hope f/Charlie Puth)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m ax \u001B[38;5;241m=\u001B[39m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mgca()\n\u001B[1;32m      3\u001B[0m df_brn_instances[(df_brn_instances[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcall_letters\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWPGB-FM\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m&\u001B[39m (df_brn_instances[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmediabase_id\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2466281\u001B[39m) \u001B[38;5;241m&\u001B[39m (\u001B[38;5;241m~\u001B[39mpd\u001B[38;5;241m.\u001B[39misna(df_brn_instances[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpop\u001B[39m\u001B[38;5;124m'\u001B[39m]))]\u001B[38;5;241m.\u001B[39mset_index([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweek_dt\u001B[39m\u001B[38;5;124m'\u001B[39m])[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mddl_metric\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mplot(ax\u001B[38;5;241m=\u001B[39max, marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mo\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m ax1\u001B[38;5;241m=\u001B[39max\u001B[38;5;241m.\u001B[39mtwinx()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Inspect Data for Gabby Barrett (I Hope f/Charlie Puth)\n",
    "ax = plt.gca()\n",
    "df_brn_instances[(df_brn_instances['call_letters'] == 'WPGB-FM') & (df_brn_instances['mediabase_id'] == 2466281) & (~pd.isna(df_brn_instances['pop']))].set_index(['week_dt'])['ddl_metric'].plot(ax=ax, marker='o')\n",
    "ax1=ax.twinx()\n",
    "df_brn_instances[(df_brn_instances['call_letters'] == 'WPGB-FM') & (df_brn_instances['mediabase_id'] == 2466281) & (~pd.isna(df_brn_instances['pop']))].set_index(['week_dt'])['stream_count'].rolling(4).mean().plot(ax=ax1, marker='^')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Plot pop/ddl/fav, f2b, spins(weekly, market), streams"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyze candidate population for burnout analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DDL and F2B analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
