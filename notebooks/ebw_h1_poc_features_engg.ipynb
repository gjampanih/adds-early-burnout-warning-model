{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='white')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### setup db connection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "def postgresql_engine(user, pwd, host, port, dbname):\n",
    "    # Need psycopg2-binary package\n",
    "    sql_engine = create_engine('postgres://' + user + ':' + pwd + '@' + host + ':' + port + '/' + dbname, echo=False)\n",
    "    return sql_engine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DB username & password\n",
    "import getpass\n",
    "\n",
    "username = getpass.getpass()\n",
    "password = getpass.getpass()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# misc db parameters\n",
    "url = 'adds-postgres-dev.cfgztrijqgvp.us-east-1.rds.amazonaws.com'\n",
    "database = 'musiclab'\n",
    "port = '5432'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create DB engine\n",
    "engine = postgresql_engine(username, password, url, port, database)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### read in raw features from postgres DB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read raw features table\n",
    "query_raw_features = '''\n",
    "Select *\n",
    "from adds_temp.ebw_raw_features_h1 as eh\n",
    "--where extract (year from eh.song_release_date) >= 2020\n",
    "'''\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        df_raw_features = pd.read_sql(query_raw_features, con=conn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# write to pickle file\n",
    "# df_raw_features.to_pickle('ebw_df_raw_features_h1.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read in pickle file\n",
    "df_raw_features = pd.read_pickle('ebw_df_raw_features_h1.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# explicit cast for date related fields\n",
    "date_cols = ['week_dt', 'song_release_date', 'hit_tag_date', 'first_spin_date', 'last_spin_date', 'ftq_date',\n",
    "             'last_callout_date', 'first_callout_date']\n",
    "\n",
    "df_raw_features[date_cols] = df_raw_features[date_cols].apply(pd.to_datetime)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sort data\n",
    "df_raw_features.sort_values(by=['mediabase_id', 'call_letters', 'week_dt'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### calculated fields"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a dictionary of computed columns to create\n",
    "computed_cols = {\n",
    "    'cuml_song_station_spins_non_on': lambda df: df.groupby(['mediabase_id', 'call_letters'])['song_station_spins_non_on'].cumsum(),\n",
    "    'weeks_since_first_spins': lambda df: (df['week_dt'] - df['first_spin_date']) / np.timedelta64(1, 'W'),\n",
    "    'weeks_since_release': lambda df: np.round((df['week_dt'] - df['song_release_date']) / np.timedelta64(1, 'W')),\n",
    "    'weeks_since_hit': lambda df: (df['week_dt'] - df['hit_tag_date']) / np.timedelta64(1, 'W'),\n",
    "    'weeks_bw_ftq_first_spins': lambda df: (df['ftq_date'] - df['first_spin_date']) / np.timedelta64(1, 'W'),\n",
    "    'weeks_bw_top_quintiles': lambda df: (df['hit_tag_date'] - df['ftq_date']) / np.timedelta64(1, 'W'),\n",
    "    'weeks_bw_ddl_thresh_cross': lambda df: (df['ddl_over_thresh_dt_second'] - df['ddl_over_thresh_dt_first']) / np.timedelta64(1, 'W'),\n",
    "    'market_spins_propn': lambda df: df['song_station_spins_non_on'] / df['song_market_spins_non_on'],\n",
    "    'artist_spins_propn': lambda df: df['song_station_spins_non_on'] / df['artist_station_spins_non_on']\n",
    "}\n",
    "\n",
    "# Use assign with a dictionary comprehension to create the computed columns\n",
    "df_raw_features = df_raw_features.assign(**{col_name: func(df_raw_features) for col_name, func in computed_cols.items()})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a sub-dataframe containing only the rows where week_dt equals hit_tag_date\n",
    "mask = df_raw_features['week_dt'] == df_raw_features['hit_tag_date']\n",
    "sub_df = df_raw_features.loc[mask, ['mediabase_id', 'call_letters', 'week_dt', 'cuml_song_station_spins_non_on']]\n",
    "sub_df = sub_df.set_index(['mediabase_id', 'call_letters'])\n",
    "\n",
    "# Join the sub-dataframe back onto the original dataframe\n",
    "df_raw_features = df_raw_features.join(sub_df, on=['mediabase_id', 'call_letters'], rsuffix='_at_hit', how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a sub-dataframe containing only the rows where week_dt equals ftq_date\n",
    "mask = df_raw_features['week_dt'] == df_raw_features['ftq_date']\n",
    "sub_df = df_raw_features.loc[mask, ['mediabase_id', 'call_letters', 'week_dt', 'cuml_song_station_spins_non_on']]\n",
    "sub_df = sub_df.set_index(['mediabase_id', 'call_letters'])\n",
    "\n",
    "# Join the sub-dataframe back onto the original dataframe\n",
    "df_raw_features = df_raw_features.join(sub_df, on=['mediabase_id', 'call_letters'], rsuffix='_at_ftq', how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter rows where week_dt equals ddl_over_thresh_dt_first\n",
    "mask = df_raw_features['week_dt'] == df_raw_features['ddl_over_thresh_dt_first']\n",
    "sub_df = df_raw_features.loc[mask, ['mediabase_id', 'call_letters', 'week_dt', 'cuml_song_station_spins_non_on']]\n",
    "sub_df = sub_df.set_index(['mediabase_id', 'call_letters'])\n",
    "\n",
    "# Join sub-dataframe to original dataframe\n",
    "df_raw_features = df_raw_features.join(sub_df, on=['mediabase_id', 'call_letters'], rsuffix='_at_pre_burnout',\n",
    "                                       how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter rows where week_dt equals ddl_over_thresh_dt_second\n",
    "mask = df_raw_features['week_dt'] == df_raw_features['ddl_over_thresh_dt_second']\n",
    "sub_df = df_raw_features.loc[mask, ['mediabase_id', 'call_letters', 'week_dt', 'cuml_song_station_spins_non_on']]\n",
    "sub_df = sub_df.set_index(['mediabase_id', 'call_letters'])\n",
    "\n",
    "# Join sub-dataframe to original dataframe\n",
    "df_raw_features = df_raw_features.join(sub_df, on=['mediabase_id', 'call_letters'], rsuffix='_at_burnout', how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# measures spins to burnout after song turns into a hit\n",
    "df_raw_features['spins_to_burnout_from_hit'] = df_raw_features['cuml_song_station_spins_non_on_at_burnout'] -\\\n",
    "                                               df_raw_features['cuml_song_station_spins_non_on_at_hit']\n",
    "\n",
    "# measure spins to hit from ftq\n",
    "df_raw_features['spins_to_hit_from_ftq'] = df_raw_features['cuml_song_station_spins_non_on_at_hit'] -\\\n",
    "                                           df_raw_features['cuml_song_station_spins_non_on_at_ftq']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_raw_features['hit_spins_bucket'] = pd.cut(df_raw_features['cuml_song_station_spins_non_on_at_hit'], np.arange(0,\n",
    "                                                                                                                 np.max(\n",
    "                                                                                                                     df_raw_features[\n",
    "                                                                                                                         'cuml_song_station_spins_non_on_at_hit']),\n",
    "                                                                                                                 250))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_raw_features['hit_spins_bucket']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### extract unique hit information (spins/dates)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# de-dupe raw features to obtain unique hit info\n",
    "id_cols = ['mediabase_id', 'call_letters']\n",
    "date_cols = ['song_release_date', 'song_release_year', 'ftq_date', 'hit_tag_date', 'ddl_over_thresh_dt_first',\n",
    "             'ddl_over_thresh_dt_second']\n",
    "weeks_cols = ['weeks_bw_ftq_first_spins', 'weeks_bw_top_quintiles']\n",
    "spins_cols = ['cuml_song_station_spins_non_on_at_ftq', 'cuml_song_station_spins_non_on_at_hit',\n",
    "              'cuml_song_station_spins_non_on_at_pre_burnout', 'cuml_song_station_spins_non_on_at_burnout',\n",
    "              'spins_to_hit_from_ftq', 'spins_to_burnout_from_hit']\n",
    "\n",
    "# create dataframe with unique hit information\n",
    "df_hits_tracker = df_raw_features[id_cols + date_cols + weeks_cols + spins_cols].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hits_tracker"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# determine spins cutoff for end of burn monitoring\n",
    "df_hits_tracker.groupby(['song_release_year']).apply(lambda x: [len(x), np.nanquantile(x['spins_to_burnout_from_hit'], 0.05), np.nanquantile(x['spins_to_burnout_from_hit'], 0.95), (x['spins_to_burnout_from_hit'] > 2500).sum(),\n",
    "                                                                (x['spins_to_burnout_from_hit'] > 2500).sum() / len(x)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask = df_hits_tracker['spins_to_burnout_from_hit'] < 150\n",
    "df_hits_tracker.loc[mask]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the above information about 2-3% of the songs which experienced burnout in 2020 and 2021 took more than 2500 spins after turning into a hit. 2500 spins seems to be a reasonable cutoff for end of burnout monitoring"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define censoring flag\n",
    "burn_end_spins_cutoff = 2500\n",
    "df_hits_tracker['censoring_flg'] = ~(pd.isna(df_hits_tracker['ddl_over_thresh_dt_second']) | (\n",
    "            df_hits_tracker['spins_to_burnout_from_hit'] > burn_end_spins_cutoff))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hits_tracker.groupby(['song_release_year', 'censoring_flg'])['mediabase_id'].count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### feature engineering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rolling_weeks = [1, 4, 8 ,13, 26]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### pop score related columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pop_cols = [col for col in df_raw_features.columns if\n",
    "            (('_pop' in col) or ('_ddl' in col) or ('_fav' in col)) and ('weeks_' not in col)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pop_cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### rolling statistics look back"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for win_len in rolling_weeks:\n",
    "    for col in pop_cols:\n",
    "        col_name = f\"{col}_prior_{win_len}wk\"\n",
    "        roll_col = df_raw_features.groupby(['mediabase_id', 'call_letters'])[col].rolling(window=win_len, min_periods=0)\n",
    "        df_raw_features[f\"{col_name}_min\"] = (roll_col.min().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_max\"] = (roll_col.max().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_mean\"] = (roll_col.mean().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_std\"] = (roll_col.std().shift(1).droplevel([0,1])).ffill()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mask = (df_raw_features['mediabase_id'] == 1086587) & (df_raw_features['call_letters'] == 'KHTS-FM')\n",
    "sel_cols = ['song_format_pop','song_format_pop_prior_4wk_mean', 'song_format_pop_prior_13wk_mean', 'song_format_pop_prior_26wk_mean', 'song_format_pop_prior_8wk_mean', 'song_format_pop_prior_1wk_mean']\n",
    "plt.scatter(df_raw_features.loc[mask, 'week_dt'], df_raw_features.loc[mask, sel_cols[0]], label=sel_cols[0])\n",
    "plt.plot(df_raw_features.loc[mask, 'week_dt'], df_raw_features.loc[mask, sel_cols[1]], label=sel_cols[1])\n",
    "plt.plot(df_raw_features.loc[mask, 'week_dt'], df_raw_features.loc[mask, sel_cols[2]], label=sel_cols[2])\n",
    "plt.plot(df_raw_features.loc[mask, 'week_dt'], df_raw_features.loc[mask, sel_cols[3]], label=sel_cols[3])\n",
    "plt.plot(df_raw_features.loc[mask, 'week_dt'], df_raw_features.loc[mask, sel_cols[4]], label=sel_cols[4])\n",
    "plt.plot(df_raw_features.loc[mask, 'week_dt'], df_raw_features.loc[mask, sel_cols[5]], label=sel_cols[5])\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### rolling stats from ftq to hit\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in pop_cols:\n",
    "    col_name = f\"{col}_ftq_to_hit\"\n",
    "    col_names = [f\"{col_name}_min\", f\"{col_name}_max\", f\"{col_name}_mean\", f\"{col_name}_std\"]\n",
    "    mask = (df_raw_features['week_dt'] >= df_raw_features['week_dt_at_ftq']) & (\n",
    "            df_raw_features['week_dt'] <= df_raw_features['week_dt_at_hit'])\n",
    "    df_sub = df_raw_features.loc[mask]\n",
    "    df_sub_grpd = df_sub.groupby(['mediabase_id', 'call_letters'])[col]\n",
    "    df_temp = pd.concat([df_sub_grpd.min(), df_sub_grpd.max(), df_sub_grpd.mean(), df_sub_grpd.std()], axis=1)\n",
    "    df_temp.columns=col_names\n",
    "    df_raw_features = df_raw_features.join(df_temp, on =['mediabase_id', 'call_letters'], how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### spins related information"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spins_cols = [col for col in df_raw_features.columns if\n",
    "              ('_spins' in col) and ('cuml_' not in col) and ('_bucket' not in col) and ('_propn' not in col) and (\n",
    "                      'weeks_' not in col)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spins_cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### rolling statistics look back"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for win_len in rolling_weeks:\n",
    "    for col in spins_cols:\n",
    "        col_name = f\"{col}_prior_{win_len}wk\"\n",
    "        roll_col = df_raw_features.groupby(['mediabase_id', 'call_letters'])[col].rolling(window=win_len, min_periods=0)\n",
    "        df_raw_features[f\"{col_name}_min\"] = (roll_col.min().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_max\"] = (roll_col.max().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_mean\"] = (roll_col.mean().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_std\"] = (roll_col.std().shift(1).droplevel([0,1])).ffill()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### rolling stats from ftq to hit\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in spins_cols:\n",
    "    col_name = f\"{col}_ftq_to_hit\"\n",
    "    col_names = [f\"{col_name}_min\", f\"{col_name}_max\", f\"{col_name}_mean\", f\"{col_name}_std\"]\n",
    "    mask = (df_raw_features['week_dt'] >= df_raw_features['week_dt_at_ftq']) & (\n",
    "            df_raw_features['week_dt'] <= df_raw_features['week_dt_at_hit'])\n",
    "    df_sub = df_raw_features.loc[mask]\n",
    "    df_sub_grpd = df_sub.groupby(['mediabase_id', 'call_letters'])[col]\n",
    "    df_temp = pd.concat([df_sub_grpd.min(), df_sub_grpd.max(), df_sub_grpd.mean(), df_sub_grpd.std()], axis=1)\n",
    "    df_temp.columns=col_names\n",
    "    df_raw_features = df_raw_features.join(df_temp, on =['mediabase_id', 'call_letters'], how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### stream related data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stream_cols = [col for col in df_raw_features.columns if '_unv' in col]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stream_cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### rolling statistics look back"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for win_len in rolling_weeks:\n",
    "    for col in stream_cols:\n",
    "        col_name = f\"{col}_prior_{win_len}wk\"\n",
    "        roll_col = df_raw_features.groupby(['mediabase_id', 'call_letters'])[col].rolling(window=win_len, min_periods=0)\n",
    "        df_raw_features[f\"{col_name}_min\"] = (roll_col.min().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_max\"] = (roll_col.max().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_mean\"] = (roll_col.mean().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_std\"] = (roll_col.std().shift(1).droplevel([0,1])).ffill()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### rolling stats from ftq to hit\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in stream_cols:\n",
    "    col_name = f\"{col}_ftq_to_hit\"\n",
    "    col_names = [f\"{col_name}_min\", f\"{col_name}_max\", f\"{col_name}_mean\", f\"{col_name}_std\"]\n",
    "    mask = (df_raw_features['week_dt'] >= df_raw_features['week_dt_at_ftq']) & (\n",
    "            df_raw_features['week_dt'] <= df_raw_features['week_dt_at_hit'])\n",
    "    df_sub = df_raw_features.loc[mask]\n",
    "    df_sub_grpd = df_sub.groupby(['mediabase_id', 'call_letters'])[col]\n",
    "    df_temp = pd.concat([df_sub_grpd.min(), df_sub_grpd.max(), df_sub_grpd.mean(), df_sub_grpd.std()], axis=1)\n",
    "    df_temp.columns=col_names\n",
    "    df_raw_features = df_raw_features.join(df_temp, on =['mediabase_id', 'call_letters'], how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### proportion related data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "propn_cols = [col for col in df_raw_features.columns if 'propn' in col]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "propn_cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### rolling statistics look back"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for win_len in rolling_weeks:\n",
    "    for col in propn_cols:\n",
    "        col_name = f\"{col}_prior_{win_len}wk\"\n",
    "        roll_col = df_raw_features.groupby(['mediabase_id', 'call_letters'])[col].rolling(window=win_len, min_periods=0)\n",
    "        df_raw_features[f\"{col_name}_min\"] = (roll_col.min().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_max\"] = (roll_col.max().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_mean\"] = (roll_col.mean().shift(1).droplevel([0,1])).ffill()\n",
    "        df_raw_features[f\"{col_name}_std\"] = (roll_col.std().shift(1).droplevel([0,1])).ffill()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### rolling stats from ftq to hit\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in propn_cols:\n",
    "    col_name = f\"{col}_ftq_to_hit\"\n",
    "    col_names = [f\"{col_name}_min\", f\"{col_name}_max\", f\"{col_name}_mean\", f\"{col_name}_std\"]\n",
    "    mask = (df_raw_features['week_dt'] >= df_raw_features['week_dt_at_ftq']) & (\n",
    "            df_raw_features['week_dt'] <= df_raw_features['week_dt_at_hit'])\n",
    "    df_sub = df_raw_features.loc[mask]\n",
    "    df_sub_grpd = df_sub.groupby(['mediabase_id', 'call_letters'])[col]\n",
    "    df_temp = pd.concat([df_sub_grpd.min(), df_sub_grpd.max(), df_sub_grpd.mean(), df_sub_grpd.std()], axis=1)\n",
    "    df_temp.columns=col_names\n",
    "    df_raw_features = df_raw_features.join(df_temp, on =['mediabase_id', 'call_letters'], how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# propogate censoring flag back to raw features\n",
    "join_cols = ['mediabase_id', 'call_letters']\n",
    "df_sub = df_hits_tracker.set_index(join_cols)['censoring_flg']\n",
    "\n",
    "df_raw_features = df_raw_features.join(df_sub, on=join_cols, how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hits_tracker.to_pickle('ebw_hits_tracker_h1.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_raw_features.to_pickle('ebw_temp_features_h1.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_raw_features = pd.read_pickle('ebw_temp_features_h1.pkl')\n",
    "df_hits_tracker = pd.read_pickle('ebw_hits_tracker_h1.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_raw_features['spins_to_burnout_from_hit'].drop_duplicates().plot(kind='box')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}